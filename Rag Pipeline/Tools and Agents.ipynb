{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load wikipdia tool,Arxiv Tool and make a tool but firstly in this case load the data,chunks,embedd ,store in db,make retriver from db then finally create a tool from it>>make a final tool by combining alll thse three in a single tool,just by passing it as a list\n",
    "\n",
    "Load chat llm model like llama2 from ollama>>import chatprompt template from langchain hub\n",
    "\n",
    "Make Agents by passsing llm,prompt and tool as parameter in create_openai_tools_agent()\n",
    "then create Agent Executor by passing the tools and agents in AgentExecutor()\n",
    "Finally invoke by Agent Executor to get the reponses from the desired tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun  # Premade LangChain Tool\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Machine learning\\nSummary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.run(\"What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What it is:\n",
    "WikipediaQueryRun is a LangChain Tool that knows how to use WikipediaAPIWrapper to search Wikipedia and return results.\n",
    "\n",
    "A Tool in LangChain = a function wrapped with some metadata (like its name, description, input type) so an agent or you can call it easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are connecting your code with Wikipedia using LangChain‚Äôs built-in tools.\n",
    "\n",
    "Here‚Äôs what each part is really doing in plain words:\n",
    "\n",
    "WikipediaAPIWrapper(...) ‚Üí this is like a helper that knows how to go to Wikipedia, search for something, and bring back the content.\n",
    "\n",
    "top_k_results=1 ‚Üí bring back only the top 1 most relevant page.\n",
    "\n",
    "doc_content_chars_max=200 ‚Üí don‚Äôt bring the whole article, just the first 200 characters (to save space).\n",
    "\n",
    "WikipediaQueryRun(api_wrapper=api_wrapper) ‚Üí this wraps the helper into a tool that LangChain (or you) can call directly. Think of it like a ready-made function: ‚Äúsearch Wikipedia and return text.‚Äù\n",
    "\n",
    "wiki.name ‚Üí this just gives the name of the tool, which is useful if you plug it into an agent (so the agent knows which tool it is using).\n",
    "\n",
    "üëâ In very simple terms:\n",
    "You‚Äôve created a mini search engine for Wikipedia inside LangChain. When you call it, it will:\n",
    "\n",
    "take your question (e.g., ‚ÄúWhat is Python programming?‚Äù)\n",
    "\n",
    "search Wikipedia\n",
    "\n",
    "return the first 200 characters of the top matching page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created Tool from Langsmith Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Users\\vishal.puri\\AppData\\Local\\Temp\\ipykernel_20212\\2444006978.py:9: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  vectordb=FAISS.from_documents(documents[:1],OllamaEmbeddings())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002416E9677D0>, search_kwargs={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents[:1],OllamaEmbeddings())\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load>>Chunks>>Embedd>>Store in vector db>>make retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\n",
    "                      \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get started with LangSmith - Docs by LangChainOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...‚åòKLangSmithPlatform for LLM observability and evaluationOverviewQuickstartsTrace an applicationEvaluate an applicationTest promptsAPI & SDKsAPI referencePython SDKJS/TS SDKPricingPlansPricing FAQOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...‚åòKGitHubForumForumSearch...NavigationGet started with LangSmithGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumGet started with LangSmithCopy pageCopy pageLangSmith is a platform for building production-grade LLM applications. Monitor and evaluate your application, so you can ship quickly and with confidence.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.run(\"what is Langsmith?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ‚Üí from langchain.tools.retriever import create_retriever_tool brings in the helper to turn a retriever into a LangChain tool.\n",
    "\n",
    "Tool creation ‚Üí retriever_tool = create_retriever_tool(...) makes the tool object.\n",
    "\n",
    "First argument ‚Äì retriever ‚Üí your existing retriever (e.g., from a vector database) that fetches relevant documents for a query.\n",
    "\n",
    "Second argument ‚Äì \"langsmith_search\" ‚Üí the tool‚Äôs name, used by agents to identify and call it.\n",
    "\n",
    "Third argument ‚Äì description ‚Üí \"Search for information about LangSmith...\" tells the agent when to use this tool, guiding its decision process.\n",
    "\n",
    "Under the hood ‚Üí wraps the retriever so it works like a standard tool with .name, .description, and .run(query).\n",
    "\n",
    "When called ‚Üí it executes retriever.get_relevant_documents(query) and returns text chunks.\n",
    "\n",
    "Usage ‚Üí integrate retriever_tool into an agent so the agent can automatically search LangSmith-related info whenever needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premade Arxiv Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2021-06-15\\nTitle: Deep Reinforcement Learning for Conservation Decisions\\nAuthors: Marcus Lapeyrolerie, Melissa S. Chapman, Kari E. A. Norman, Carl Boettiger\\nSummary: Can machine learning he'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.run(\"What is deep learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition ‚Üí arXiv (pronounced ‚Äúarchive‚Äù) is a free, open-access online repository for research papers.\n",
    "\n",
    "Domain ‚Üí Mainly covers physics, mathematics, computer science, quantitative biology, quantitative finance, electrical engineering, statistics, and economics.\n",
    "\n",
    "Founded ‚Üí Started in 1991 by physicist Paul Ginsparg at Los Alamos, later moved to Cornell University.\n",
    "\n",
    "Purpose ‚Üí Lets researchers share their scientific work quickly before peer-reviewed journal publication.\n",
    "\n",
    "Access ‚Üí Anyone can read and download papers at no cost, no subscription required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishal.puri\\AppData\\Local\\Temp\\ipykernel_20212\\3767266266.py:2: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "llm = ChatOllama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the prompt to use - we can modify this!>>Already made prompts from langchain hub\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000024156EB2CA0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000024156EB2CA0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOllama(), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\venvs\\\\myenv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002416E9E3BA0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002416E9677D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002416E9E3C40>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002416E9677D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! I'm here to help you understand what deep learning is. Deep learning is a subfield of machine learning that involves the use of artificial neural networks to model and solve complex problems. These networks are designed to mimic the structure and function of the human brain, with layers of interconnected nodes (neurons) that process and transmit information.\n",
      "\n",
      "Deep learning algorithms are capable of learning and improving on their own by analyzing large amounts of data, without being explicitly programmed for a particular task. This makes them particularly useful for tasks such as image and speech recognition, natural language processing, and autonomous driving.\n",
      "\n",
      "Some key features of deep learning include:\n",
      "\n",
      "1. Artificial neural networks: Deep learning algorithms are based on artificial neural networks, which are modeled after the structure and function of the human brain. These networks have multiple layers of interconnected nodes (neurons) that process and transmit information.\n",
      "2. Learning and improvement: Deep learning algorithms can learn and improve on their own by analyzing large amounts of data, without being explicitly programmed for a particular task.\n",
      "3. Large amounts of data: Deep learning algorithms require large amounts of data to train the network and improve its performance.\n",
      "4. Automation: Deep learning algorithms can automate tasks such as image recognition, natural language processing, and autonomous driving.\n",
      "5. Accuracy: Deep learning algorithms have been shown to be highly accurate in a variety of applications, including image recognition, speech recognition, and natural language processing.\n",
      "6. Flexibility: Deep learning algorithms can be used for a wide range of tasks, including image classification, speech recognition, and natural language processing.\n",
      "7. Scalability: Deep learning algorithms can be scaled up to handle large amounts of data and complex tasks.\n",
      "8. Ability to learn from raw data: Deep learning algorithms can learn from raw data without the need for manual feature engineering.\n",
      "9. Ability to generalize: Deep learning algorithms can generalize well to new, unseen data.\n",
      "10. Potential for autonomous decision-making: Deep learning algorithms have the potential to make autonomous decisions based on the data they are trained on.\n",
      "\n",
      "Overall, deep learning is a powerful tool for solving complex problems and has been successfully applied to a wide range of applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is deep learning?',\n",
       " 'output': \"Hello! I'm here to help you understand what deep learning is. Deep learning is a subfield of machine learning that involves the use of artificial neural networks to model and solve complex problems. These networks are designed to mimic the structure and function of the human brain, with layers of interconnected nodes (neurons) that process and transmit information.\\n\\nDeep learning algorithms are capable of learning and improving on their own by analyzing large amounts of data, without being explicitly programmed for a particular task. This makes them particularly useful for tasks such as image and speech recognition, natural language processing, and autonomous driving.\\n\\nSome key features of deep learning include:\\n\\n1. Artificial neural networks: Deep learning algorithms are based on artificial neural networks, which are modeled after the structure and function of the human brain. These networks have multiple layers of interconnected nodes (neurons) that process and transmit information.\\n2. Learning and improvement: Deep learning algorithms can learn and improve on their own by analyzing large amounts of data, without being explicitly programmed for a particular task.\\n3. Large amounts of data: Deep learning algorithms require large amounts of data to train the network and improve its performance.\\n4. Automation: Deep learning algorithms can automate tasks such as image recognition, natural language processing, and autonomous driving.\\n5. Accuracy: Deep learning algorithms have been shown to be highly accurate in a variety of applications, including image recognition, speech recognition, and natural language processing.\\n6. Flexibility: Deep learning algorithms can be used for a wide range of tasks, including image classification, speech recognition, and natural language processing.\\n7. Scalability: Deep learning algorithms can be scaled up to handle large amounts of data and complex tasks.\\n8. Ability to learn from raw data: Deep learning algorithms can learn from raw data without the need for manual feature engineering.\\n9. Ability to generalize: Deep learning algorithms can generalize well to new, unseen data.\\n10. Potential for autonomous decision-making: Deep learning algorithms have the potential to make autonomous decisions based on the data they are trained on.\\n\\nOverall, deep learning is a powerful tool for solving complex problems and has been successfully applied to a wide range of applications.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is deep learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Certainly! Langsmith is a fictional character I created for the purpose of this interaction. He is a friendly and helpful assistant who is here to assist you with any questions or tasks you may have.\n",
      "\n",
      "Langsmith is a robot with a sleek and modern design, equipped with advanced technology that allows him to perform a wide range of tasks. He has a cheerful and polite demeanor, and is always eager to help with a smile on his face.\n",
      "\n",
      "Some of Langsmith's abilities include:\n",
      "\n",
      "* Answering questions on a variety of topics, from science and technology to history and culture.\n",
      "* Assisting with tasks such as scheduling appointments, making reservations, or sending messages.\n",
      "* Providing suggestions or recommendations for things like travel destinations, books to read, or movies to watch.\n",
      "* Offering language translation services, allowing him to communicate with people from different cultures and backgrounds.\n",
      "* Helping with problem-solving tasks, such as brainstorming ideas or finding solutions to complex issues.\n",
      "\n",
      "Overall, Langsmith is a versatile and reliable assistant who is always happy to help with whatever you may need! Is there anything specific you would like to know or discuss?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': \"\\nCertainly! Langsmith is a fictional character I created for the purpose of this interaction. He is a friendly and helpful assistant who is here to assist you with any questions or tasks you may have.\\n\\nLangsmith is a robot with a sleek and modern design, equipped with advanced technology that allows him to perform a wide range of tasks. He has a cheerful and polite demeanor, and is always eager to help with a smile on his face.\\n\\nSome of Langsmith's abilities include:\\n\\n* Answering questions on a variety of topics, from science and technology to history and culture.\\n* Assisting with tasks such as scheduling appointments, making reservations, or sending messages.\\n* Providing suggestions or recommendations for things like travel destinations, books to read, or movies to watch.\\n* Offering language translation services, allowing him to communicate with people from different cultures and backgrounds.\\n* Helping with problem-solving tasks, such as brainstorming ideas or finding solutions to complex issues.\\n\\nOverall, Langsmith is a versatile and reliable assistant who is always happy to help with whatever you may need! Is there anything specific you would like to know or discuss?\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "I apologize, but I don't have access to the latest scientific papers or research studies. However, I can try to help you find the information you're looking for. Can you provide me with more details about the paper you're interested in, such as the title, author, or a brief summary? That way, I can try to help you locate it or provide you with relevant information.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the paper 1605.08386 about?\",\n",
       " 'output': \"\\nI apologize, but I don't have access to the latest scientific papers or research studies. However, I can try to help you find the information you're looking for. Can you provide me with more details about the paper you're interested in, such as the title, author, or a brief summary? That way, I can try to help you locate it or provide you with relevant information.\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What's the paper 1605.08386 about?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
